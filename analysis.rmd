---
title: "Analysis of Genre Audio Features"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
library(spotifyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(ggforce)
library(tibble)
```
# Introduction of Corpus

My corpus is a collection with songs of three different genres, namely: Afro House, Deep House, and Melodic House. These genres are all subgenres of house, which makes them interesting to study to find out what distinguishes these genres. Each genre has its own unique blend of rhythm, melodies, and textures which make them very suitable for analysis.

Afro House, with its rhythmic energy and African influences, contrasts with Melodic House's emotive soundscapes and Deep House's soulful grooves. This selection aims to explore the auditory and emotional distinctions and intersections among these genres. I expect differences in their rhythmic structure; Afro House has more complex rhythms, whereas Deep House and Melodic House have simpler rhythms. The mood of the genres also differs, from Deep House's mellow vibes to Afro House's energy and Melodic House's ethereal qualities, yet their base structure is similar.

My corpus consists of dozens of songs for every genre, aiming for a diverse range of artists and songs that represent each genre. However a potential gap in my corpus is the focus on relatively recent releases which does not take the history of each genre into account. Also my corpus does potentially miss niche songs that could offer additional insights into each genre.

Typical songs for each genre are: Ben Bohmer - Beyond Beliefs for Melodic House, Rampa - Champion for Afro House, and Mahalo - Home for Deep House, embodying each genre's core values. Atypical songs like Notre Dame - Yumi - edit for Melodic House, Sebjak - Somebody - edit for Afro House, and Hannah Laing - Good Love for Deep House, are chosen for their unusual rhythm and tempo, offering additional insights into each genre.

# Harmony in Motion: Exploring Genre Energies and Emotions {.tabset}
## Visualization and Description of first visualisation
```{r, align='center'}	
Sys.setenv(SPOTIFY_CLIENT_ID = Sys.getenv("SPOTIFY_CLIENT_ID"))
Sys.setenv(SPOTIFY_CLIENT_SECRET = Sys.getenv("SPOTIFY_CLIENT_SECRET"))
access_token <- get_spotify_access_token()

# Fetching data
playlist_id <- "1RhRAqYJA1mwmBtk4mXRju"
username <- "quintijn.kroesbergen"
all_audio_features_df <- get_playlist_audio_features(username, playlist_uris = c(playlist_id), authorization = access_token)

# Assigning genres
all_audio_features_df$genre <- NA
all_audio_features_df$genre[1:107] <- 'Afro House'
all_audio_features_df$genre[108:206] <- 'Deep House'
all_audio_features_df$genre[207:284] <- 'Melodic House'

# Plotting the graph
ggplot(all_audio_features_df, aes(x = energy, y = valence, color = genre)) +
  geom_point() +
  labs(title = "Energy vs Valence by Genre",
       x = "Energy",
       y = "Valence",
       color = "Genre") +
  scale_color_manual(values = c('Afro House' = 'blue', 'Deep House' = 'red', 'Melodic House' = 'green')) +
  theme_minimal() +
  theme(legend.position = "right")
```

***
This plot is a scatterplot displaying the relationship between 'Energy' and 'Valence' for the three different genres of music: Afro House, Deep House, and Melodic House. Each panel represents one of the genres, plotted with 'Energy' on the x-axis and 'Valence' on the y-axis. The data points for Afro House are colored blue, for Deep House they are red, and for Melodic House they are green. The spread of data points in each genre-specific panel indicates the distribution of the tracks according to their energy and valence characteristics within that genre.

***
It is interesting to see how the three different genres I chose for my analysis compare in terms of their energy and valence. This plot provides insights into the emotional characteristics of each genre. For example, we can visually conclude that Melodic House is considered the least positive of the three genres according to Spotify. This makes sense since it's the more emotional genre.

# Sonic Spectrum: Mapping Pitch Class Intensity Over Time
## Visualisation
```{r, align='center'}
track_id <- "1MvLmHeLkaNgUScgbUVnWJ"
audio_analysis <- get_track_audio_analysis(track_id, authorization = access_token)
# Assuming `audio_analysis` has already been retrieved
segments <- audio_analysis$segments


# Initialize an empty data frame to store the long-format pitch data
pitch_data_long <- tibble()

# Loop through each segment to transform pitch data into a long format
for(i in 1:nrow(segments)) {
  segment_pitch_data <- tibble(
    start = segments$start[i],
    duration = segments$duration[i],
    pitch_class = c("C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"),
    intensity = segments$pitches[[i]]
  )
  pitch_data_long <- bind_rows(pitch_data_long, segment_pitch_data)
}

# Now, pitch_data_long should be in the correct format for plotting

ggplot(pitch_data_long, aes(x = start, y = pitch_class, fill = intensity)) +
  geom_tile() + # Use geom_tile() to create the heatmap
  scale_fill_gradient(low = "blue", high = "red") + # Customize the color gradient
  labs(title = "Pitch Class Intensity Over Time",
       x = "Time (s)",
       y = "Pitch Class",
       fill = "Intensity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), # Rotate x-axis labels if needed
        axis.title = element_text(size = 12),
        title = element_text(size = 14))
```

***

This plot is a heatmap that visualizes the intensity of pitch classes over time within the song "Breathing" by Ben BÃ¶hmer. The choice for this song was not because it was a pitch related outlier, but because it was a tempo related outlier. The horizontal axis represents time in seconds, and the vertical axis indicates the pitch classes. Intensity levels are depicted through a color gradient, transitioning from blue for lower intensities to red for higher intensities. 
***
